#!/usr/bin/env python3

########################################################################
# vanityhash, a hex hash fragment creation tool
# Copyright (C) 2010-2018 Ryan Finnie <ryan@finnie.org>
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
# 02110-1301, USA.
########################################################################

import sys
import hashlib
import struct
import multiprocessing
import queue
import time
import getopt
import codecs
import zlib
import copy
import random


class VanityHash:
    """VanityHash class.

    Child subprocesses will have access to the instance of this class,
    forked from the master.
    """
    version = '2.0'

    # multiprocessing queue object
    queue = multiprocessing.Queue()
    # hashlib context
    ctx = None
    # Total number of hashes searched, across all children
    total_searched = 0
    # Total number of hashes found, across all children
    total_found = 0
    # In append mode, whether the binary result has been printed yet
    printed_append = False
    # Epoch start time
    start_time = None
    # Next epoch time to display the progress
    next_progress_time = None
    # Number of real workers to be used
    workers_real = 0
    # List of zero-indexed workers to be used
    workers_real_l = []
    # Total workers in the worker set
    workers_total = 0
    # Proporition of real to total workers
    workers_real_fraction = 0.0
    # Pack type of hash candidates
    pack_type = b'=L'

    # Whether to display human-readable information to stderr
    opt_quiet = False
    # Search space, in bits
    opt_bits = 24
    # Total size containing the search space, in bits
    opt_bits_pack = 0
    # Endianness of the built container
    opt_byte_order = 'native'
    # Worker specification provided by the user
    opt_workers_s = 'guess'
    # Hash digest type
    opt_digest_type = 'md5'
    # How often to display progress information
    opt_progress_interval = 5.0
    # Whether to output the original data + the first result
    opt_append = False
    # Zero-indexed position within the hash to search
    opt_find_pos = 0
    # Whether to find the desired fragment anywhere in the hash
    opt_find_any_pos = False
    # Where to add a zeroed pack in append mode, if no match is found
    opt_append_empty = False

    def __init__(self):
        """Initialize the class."""
        # Parse getopts.
        try:
            self.parse_options()
        except RuntimeError as e:
            self.usage()
            self.log('Error: %s' % e)
            sys.exit(2)

    def main(self):
        """Main program loop."""
        # Read stdin data.
        self.read_data()

        if self.opt_find_any_pos:
            self.log('Searching for %s at any position in a %d-bit space.' % (
                self.opt_find, self.opt_bits
            ))
        else:
            self.log('Searching for %s at position %d in a %d-bit space.' % (
                self.opt_find, self.opt_find_pos, self.opt_bits
            ))

        self.start_time = time.time()

        if self.workers_total == self.workers_real:
            self.log('Spawning %d worker%s...' % (
                self.workers_real, ((self.workers_real != 1) and 's' or '')
            ), newline=False)
        else:
            self.log('Spawning %d of %d worker%s (%s)...' % (
                self.workers_real, self.workers_total, ((self.workers_total != 1) and 's' or ''),
                (','.join(str(x + 1) for x in self.workers_real_l))
            ), newline=False)

        # Spawn worker children.
        for i in self.workers_real_l:
            p = multiprocessing.Process(target=self.worker, args=(i,))
            p.name = 'Worker %d' % (i + 1)
            p.start()

        self.log('done.')

        # Loop through messages from children, occasionally reporting
        # hashing progress.
        self.next_progress_time = self.start_time + self.opt_progress_interval
        while True:
            try:
                self.process_message()
                self.report_progress()
            except KeyboardInterrupt:
                self.log('Stopping workers...')
                self.kill_children()

            if len(multiprocessing.active_children()) == 0:
                break

        if self.opt_append and self.opt_append_empty and not self.printed_append:
            sys.stdout.buffer.write(b'\x00' * int(self.opt_bits_pack / 8))
            sys.stdout.buffer.flush()
            self.printed_append = True

        # Final statistics.
        delta_time = time.time() - self.start_time
        self.log('Search finished in %02d:%02d, %d match%s found in %d%% of a %d-bit space.' % (
            (delta_time / 60), (delta_time % 60), self.total_found,
            ((self.total_found != 1) and 'es' or ''),
            ((self.total_searched - 1) / self.space_max * 100), self.opt_bits
        ))

    def worker(self, num_begin):
        """Process hash instructions in a subprocess.

        Note that the state of the class instance is the state at the
        time of the fork from the parent process.  Communication back to
        the parent is done by the queue object.
        """
        to_find = self.opt_find
        to_find_len = len(to_find)
        find_pos = self.opt_find_pos
        find_anypos = self.opt_find_any_pos
        find_pos_end = find_pos + to_find_len

        # Start out with a group of 10,000 hashes.  This will be revised
        # to be approximately 2 seconds worth of hashes.
        last_report = time.time()
        report_i = 10000
        i = num_begin

        while i <= self.space_max:
            # Take into account multiple workers when determining when
            # to end the group.
            group_num_end = i + (report_i * self.workers_total)
            if group_num_end > self.space_max:
                group_num_end = self.space_max
            group_i_begin = i

            # The actual hash->test loop is as tight as possible, and
            # hence is duplicated a bit.
            if find_anypos:
                while i <= group_num_end:
                    ctxcopy = self.ctx.copy()
                    ctxcopy.update(struct.pack(self.pack_type, i))
                    hexdigest = ctxcopy.hexdigest()
                    if hexdigest.find(to_find) > -1:
                        self.queue.put(('FOUND', (hexdigest, i)))
                    i += self.workers_total
            else:
                while i <= group_num_end:
                    ctxcopy = self.ctx.copy()
                    ctxcopy.update(struct.pack(self.pack_type, i))
                    hexdigest = ctxcopy.hexdigest()
                    if hexdigest[find_pos:find_pos_end] == to_find:
                        self.queue.put(('FOUND', (hexdigest, i)))
                    i += self.workers_total

            # Figure out how many hashes were performed, and update the
            # parent.
            report_i = (i - group_i_begin) / self.workers_total
            self.queue.put(('PROGRESS', report_i))

            # Figure out how many hashes are needed to run for the next
            # ~2 seconds.
            now = time.time()
            next_report_i = int(2 * (report_i / (now - last_report)))
            last_report = now
            report_i = next_report_i

    def pretty_number(self, n, divisor=1000, rollover=1.0, format='{number:0.02f} {prefix}'):
        if divisor == 1024:
            prefixes = ['', 'Ki', 'Mi', 'Gi', 'Ti']
        else:
            prefixes = ['', 'K', 'M', 'G', 'T']
        ppos = 0
        max_ppos = len(prefixes) - 1
        while n >= (divisor * rollover):
            ppos = ppos + 1
            n = n / float(divisor)
            if ppos >= max_ppos:
                break
        return format.format(number=n, prefix=prefixes[ppos])

    def bytes_to_hex(self, b):
        """Return a hex representation of binary byte data."""
        return codecs.encode(b, 'hex_codec').decode('ascii')

    def parse_options(self):
        """Parse and validate command-line options."""
        try:
            opts, args = getopt.getopt(sys.argv[1:], '?b:w:d:s:at:yqp:n:e', [
                'help', 'bits=', 'workers=', 'digest=', 'progress=', 'append',
                'bits-pack=', 'any-position', 'quiet', 'position=',
                'byte-order=', 'append-empty'
            ])
        except getopt.GetoptError as err:
            raise RuntimeError(str(err))
        for o, a in opts:
            if o in ('?', '--help'):
                self.usage()
                sys.exit(2)
            elif o in ('-b', '--bits'):
                self.opt_bits = int(a)
                if (self.opt_bits < 1) or (self.opt_bits > 64):
                    raise RuntimeError('Search space must be 64 bits or less')
            elif o in ('-t', '--bits-pack'):
                self.opt_bits_pack = int(a)
            elif o in ('-w', '--workers'):
                self.opt_workers_s = a
            elif o in ('-d', '--digest'):
                if a == 'sha1alt':
                    a = 'sha1'
                self.opt_digest_type = a
            elif o in ('-s', '--progress'):
                self.opt_progress_interval = float(a)
            elif o in ('-a', '--append'):
                self.opt_append = True
            elif o in ('-p', '--position'):
                self.opt_find_pos = int(a)
            elif o in ('-y', '--any-position'):
                self.opt_find_any_pos = True
            elif o in ('-q', '--quiet'):
                self.opt_quiet = True
            elif o in ('-n', '--byte-order'):
                if a in ('native', 'little', 'big'):
                    self.opt_byte_order = a
                else:
                    raise RuntimeError('Invalid byte order, must be one of: %s' % str(('native', 'little', 'big')))
            elif o in ('-e', '--append-empty'):
                self.opt_append_empty = True
            else:
                assert False, 'unhandled option %s' % o

        if len(args) < 1:
            self.usage()
            sys.exit(2)
        self.opt_find = args[0].lower()

        # Generate the container size if not specified.
        if self.opt_bits_pack == 0:
            self.opt_bits_pack = 1
            while self.opt_bits_pack < self.opt_bits:
                self.opt_bits_pack *= 2
            if self.opt_bits_pack < 8:
                self.opt_bits_pack = 8
        # Validate the container size.
        if (self.opt_bits_pack < self.opt_bits) or (self.opt_bits_pack > 64):
            raise RuntimeError('Invalid bits-pack')
        # Make sure the container size is a power of 2.
        bits_pack_bytes = int(self.opt_bits_pack / 8)
        if not (bits_pack_bytes & (bits_pack_bytes - 1)) == 0:
            raise RuntimeError('Invalid bits-pack')

        # Validate the desired hex fragment
        for i in self.opt_find:
            if i not in '0 1 2 3 4 5 6 7 8 9 a b c d e f'.split():
                raise RuntimeError('Invalid search hex string')

        # Pre-compute the largest integer to be tested.
        self.space_max = 0
        for i in range(0, self.opt_bits):
            self.space_max += 2 ** i

        # Build a pack type based on the bits_pack size.
        if self.opt_byte_order == 'little':
            self.pack_type = b'<'
        elif self.opt_byte_order == 'big':
            self.pack_type = b'>'
        else:
            self.pack_type = b'='
        if self.opt_bits_pack == 64:
            self.pack_type += b'Q'
        elif self.opt_bits_pack == 32:
            self.pack_type += b'L'
        elif self.opt_bits_pack == 16:
            self.pack_type += b'H'
        else:
            self.pack_type += b'B'

        # Build the worker options.
        if self.opt_workers_s == 'guess':
            try:
                self.opt_workers_s = str(multiprocessing.cpu_count())
            except NotImplementedError:
                self.opt_workers_s = str(1)
        if self.opt_workers_s.isdigit():
            # If a single number is given, the real and total workers
            # are the same.
            self.workers_total = int(self.opt_workers_s)
            self.workers_real_l = range(self.workers_total)
        else:
            # If a specification is given, validate and build according
            # to the specification.
            try:
                (workert, workerx) = self.opt_workers_s.split(':')
            except ValueError:
                raise RuntimeError('Invalid worker specification')
            self.workers_total = int(workert)
            for i in workerx.split(','):
                if not i.isdigit():
                    raise RuntimeError('Invalid worker specification')
                i = int(i)
                if (i > self.workers_total) or (i < 1):
                    raise RuntimeError('Invalid worker specification')
                if not (i - 1) in self.workers_real_l:
                    self.workers_real_l.append(i - 1)
                self.workers_real_l.sort()
        self.workers_real = len(self.workers_real_l)
        if (self.workers_total < 1) or (self.workers_real < 1):
            raise RuntimeError('Invalid number of workers')
        if self.workers_real > 128:
            raise RuntimeError('Cannot be more than 128 workers')
        self.workers_real_fraction = self.workers_real / self.workers_total

        # Test the hash type is valid.
        try:
            testctx = ExtendedHashlib().new(self.opt_digest_type)
        except ValueError:
            raise RuntimeError('Invalid digest type')

        # Test the position specified is correct according to the given
        # hash type.
        hexdigestsize = testctx.digest_size * 2
        maxpos = hexdigestsize - len(self.opt_find)
        if self.opt_find_pos < 0:
            self.opt_find_pos += hexdigestsize
        if self.opt_find_pos > maxpos:
            raise RuntimeError('Pattern position %d goes beyond end of %s digest' % (
                self.opt_find_pos, self.opt_digest_type.upper())
            )

    def log(self, text='', newline=True):
        """Write text to stderr."""
        if self.opt_quiet:
            return
        if newline:
            print(text, file=sys.stderr)
        else:
            print(text, file=sys.stderr, end='')

    def process_message(self):
        """Parse a received child message."""
        try:
            msg = self.queue.get(block=True, timeout=1.0)
        except queue.Empty:
            return
        if msg[0] == 'PROGRESS':
            self.total_searched += msg[1]
        elif msg[0] == 'FOUND':
            (msgdigest, msgdata) = msg[1]
            msgdata = struct.pack(self.pack_type, msgdata)
            self.log('Match found: 0x%s -> %s %s' % (
                self.bytes_to_hex(msgdata), self.opt_digest_type.upper(), msgdigest)
            )
            self.total_found += 1
            if self.opt_append:
                if not self.printed_append:
                    sys.stdout.buffer.write(msgdata)
                    sys.stdout.buffer.flush()
                    self.printed_append = True
                    self.kill_children()
            else:
                sys.stdout.write('%s %s\n' % (self.bytes_to_hex(msgdata), msgdigest))
                sys.stdout.flush()

    def read_data(self):
        """Read data from stdin and build the initial hash context."""
        self.ctx = ExtendedHashlib().new(self.opt_digest_type)
        self.log('Reading input data and adding to digest...', newline=False)
        datalen = 0
        while True:
            buf = sys.stdin.buffer.read(1024)
            if not buf:
                break
            if self.opt_append:
                sys.stdout.buffer.write(buf)
            datalen += len(buf)
            self.ctx.update(buf)
        if self.opt_append:
            sys.stdout.buffer.flush()
        self.log('done.')

        origdigest = self.ctx.copy().hexdigest()
        self.log('Original data: %d bytes, %s %s' % (datalen, self.opt_digest_type.upper(), origdigest))

    def report_progress(self):
        """Occasionally output progress statistics."""
        now = time.time()
        if not now > self.next_progress_time:
            return
        elapsed = now - self.start_time
        percent = self.total_searched / (self.space_max * self.workers_real_fraction) * 100
        if self.total_searched > 0:
            remaining = (
                (self.space_max * self.workers_real_fraction - self.total_searched) / (self.total_searched / elapsed)
            )
            estimated_time = (
                (self.space_max * self.workers_real_fraction) / (self.total_searched / elapsed)
            )
            self.log('%3d%% searched, ~%02d:%02d/%02d:%02d remaining, %s' % (
                percent,
                (remaining / 60),
                (remaining % 60),
                (estimated_time / 60),
                (estimated_time % 60),
                self.pretty_number(self.total_searched / elapsed, format='{number:0.02f} {prefix}hash/s'),
            ))
        else:
            self.log('%3d%% searched...' % percent)
        self.next_progress_time = now + self.opt_progress_interval

    def kill_children(self):
        """Kill all child subprocesses."""
        for child_process in multiprocessing.active_children():
            child_process.terminate()

    def usage(self):
        """Output usage information."""
        self.log('vanityhash version %s' % self.version)
        self.log('Copyright (C) 2010-2018 Ryan Finnie <ryan@finnie.org>')
        self.log()
        self.log('Usage:')
        self.log()
        self.log('    vanityhash [ options ] hexfragment < inputfile')
        self.log('    vanityhash --append [ options ] hexfragment < inputfile > outputfile')
        self.log()


class HashlibCRC32:
    """hashlib-compatible CRC32."""
    _crc = 0
    name = 'crc32'
    digestsize = 4
    digest_size = 4
    block_size = 1

    def copy(self):
        return copy.copy(self)

    def update(self, data):
        self._crc = zlib.crc32(data, self._crc)

    def digest(self):
        return struct.pack(b'>I', (self._crc & 0xffffffff))

    def hexdigest(self):
        return codecs.encode(self.digest(), 'hex_codec')


class HashlibAdler32:
    """hashlib-compatible Adler-32."""
    _checksum = 1
    name = 'adler32'
    digestsize = 4
    digest_size = 4
    block_size = 1

    def copy(self):
        return copy.copy(self)

    def update(self, data):
        self._checksum = zlib.adler32(data, self._checksum)

    def digest(self):
        return struct.pack(b'>I', (self._checksum & 0xffffffff))

    def hexdigest(self):
        return codecs.encode(self.digest(), 'hex_codec')


class HashlibRandom:
    """hashlib-compatible dummy random module."""
    _checksum = 0
    name = 'random'
    digestsize = 32
    digest_size = 32
    block_size = 64

    def __init__(self, digest_size=32, block_size=64):
        self.digestsize = digest_size
        self.digest_size = digest_size
        self.block_size = block_size
        self.update('')

    def copy(self):
        return copy.copy(self)

    def update(self, data):
        self._checksum = bytes([random.randint(0, 255) for x in range(self.digest_size)])

    def digest(self):
        return self._checksum

    def hexdigest(self):
        return codecs.encode(self.digest(), 'hex_codec')


class ExtendedHashlib:
    """hashlib-compatible extension system."""
    extended_algorithms = {
        'random': HashlibRandom,
        'crc32': HashlibCRC32,
        'adler32': HashlibAdler32
    }

    def __init__(self):
        if hasattr(hashlib, 'algorithms'):
            self.algorithms = (
                hashlib.algorithms +
                tuple(self.extended_algorithms.keys()))
            self._hashlib_algorithms = hashlib.algorithms
            for algo in hashlib.algorithms:
                vars(self)[algo] = getattr(hashlib, algo)
        elif hasattr(hashlib, 'algorithms_available'):
            self.algorithms_available = set(
                tuple(hashlib.algorithms_available) +
                tuple(self.extended_algorithms.keys()))
            self._hashlib_algorithms = hashlib.algorithms_available
            self.algorithms_guaranteed = hashlib.algorithms_guaranteed
            for algo in hashlib.algorithms_guaranteed:
                vars(self)[algo] = getattr(hashlib, algo)

    def new(self, algo, **kwargs):
        if algo in self.extended_algorithms:
            return self.extended_algorithms[algo](**kwargs)
        else:
            return hashlib.new(algo, **kwargs)


if __name__ == '__main__':
    vh = VanityHash()
    vh.main()
